{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c298b01-6a63-4ff2-876e-a697db93bd18",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c4d4b8-7253-4035-84fb-a66b3e148004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "import numpy as np\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddcf2c2-af93-4eda-a166-7f657d6216f5",
   "metadata": {},
   "source": [
    "# Load dataset into variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0af9944-1274-4595-af8b-60122d20cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_asteroid_data():\n",
    "    #csv_path = \"shuffled_asteroids_head.csv\"\n",
    "    csv_path = \"combined.csv\"\n",
    "    return pd.read_csv(csv_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b3b06c-cf68-4b3f-ab51-8c43d6f356f4",
   "metadata": {},
   "source": [
    "# Removing unneeded features and null features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e4de44-996b-4b03-a0b3-eb402663bc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10027 entries, 0 to 10026\n",
      "Data columns (total 35 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         10027 non-null  object \n",
      " 1   neo        10027 non-null  object \n",
      " 2   pha        10027 non-null  object \n",
      " 3   H          10027 non-null  float64\n",
      " 4   epoch      10027 non-null  float64\n",
      " 5   epoch_mjd  10027 non-null  int64  \n",
      " 6   epoch_cal  10027 non-null  float64\n",
      " 7   e          10027 non-null  float64\n",
      " 8   a          10027 non-null  float64\n",
      " 9   q          10027 non-null  float64\n",
      " 10  i          10027 non-null  float64\n",
      " 11  om         10027 non-null  float64\n",
      " 12  w          10027 non-null  float64\n",
      " 13  ma         10027 non-null  float64\n",
      " 14  ad         10027 non-null  float64\n",
      " 15  n          10027 non-null  float64\n",
      " 16  tp         10027 non-null  float64\n",
      " 17  tp_cal     10027 non-null  float64\n",
      " 18  per        10027 non-null  float64\n",
      " 19  per_y      10027 non-null  float64\n",
      " 20  moid       10027 non-null  float64\n",
      " 21  moid_ld    10027 non-null  float64\n",
      " 22  sigma_e    10027 non-null  float64\n",
      " 23  sigma_a    10027 non-null  float64\n",
      " 24  sigma_q    10027 non-null  float64\n",
      " 25  sigma_i    10027 non-null  float64\n",
      " 26  sigma_om   10027 non-null  float64\n",
      " 27  sigma_w    10027 non-null  float64\n",
      " 28  sigma_ma   10027 non-null  float64\n",
      " 29  sigma_ad   10027 non-null  float64\n",
      " 30  sigma_n    10027 non-null  float64\n",
      " 31  sigma_tp   10027 non-null  float64\n",
      " 32  sigma_per  10027 non-null  float64\n",
      " 33  class      10027 non-null  object \n",
      " 34  rms        10027 non-null  float64\n",
      "dtypes: float64(30), int64(1), object(4)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "asteroids = load_asteroid_data()\n",
    "#asteroids.head()\n",
    "asteroids = asteroids.dropna(subset=['pha'])\n",
    "asteroids = asteroids.dropna(subset=['sigma_e'])\n",
    "asteroids = asteroids.dropna(subset=['neo'])\n",
    "asteroids = asteroids.dropna(subset=['H'])\n",
    "asteroids = asteroids.dropna(subset=['ma'])\n",
    "asteroids = asteroids.drop(columns=['spkid', 'full_name', 'pdes', 'prefix', 'name', 'orbit_id', 'equinox', 'diameter', \"diameter_sigma\", \"albedo\"])\n",
    "asteroids.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc0bfc-6f92-4cd3-ba25-4d224f092d06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92dcfaed-b3cc-41f5-98ac-53ee0a590aba",
   "metadata": {},
   "source": [
    "# Converting object datatypes to numerical and standardizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88412f9f-6489-4447-8ca8-bcbb9bd58daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "#splitting features into numerical and categorical\n",
    "asteroids_num = asteroids.drop(columns=[\"id\", \"neo\", \"pha\", \"class\"])\n",
    "asteroids_id = asteroids[[\"id\"]]\n",
    "asteroids_cat = asteroids[[\"neo\", \"pha\", \"class\"]]\n",
    "\n",
    "#encode categorical features\n",
    "asteroid_cat_encoded = ordinal_encoder.fit_transform(asteroids_cat)\n",
    "\n",
    "#Normalizing numerical features\n",
    "std_scaler = StandardScaler()\n",
    "asteroid_num_scaled = std_scaler.fit_transform(asteroids_num)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde35eab-553d-45f9-b96d-8d6d39ec9468",
   "metadata": {},
   "source": [
    "# Creating features and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0918a8a-cfdf-4cc9-8f44-504fab176c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10027, 33)\n",
      "(10027,)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((asteroid_cat_encoded, asteroid_num_scaled), axis=1)\n",
    "X = np.delete(X, 2, 1)\n",
    "y = asteroid_cat_encoded[:,2]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528090d-ad59-40b9-bf1c-dbdd05470a67",
   "metadata": {},
   "source": [
    "# Training and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c72da619-a5fc-4da9-a7ee-4ac824b3b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61171946-df6f-4cdc-8ccb-813f5bdf4a82",
   "metadata": {},
   "source": [
    "# Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0453953-5f1c-41f6-af2c-035730ae17ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9506480558325024\n",
      "Micro F1 scorre:  0.9506480558325024\n",
      "Macro F1 score:  0.6539133467541507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def logistic_regression():\n",
    "    # Initialization and fitting logisitic regression\n",
    "    log_reg = LogisticRegression(solver=\"newton-cg\", random_state=42)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    #Make predictions\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "\n",
    "    #Model metrics\n",
    "    log_reg_accuracy = accuracy_score(y_test, y_pred)\n",
    "    log_reg_microf1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "    log_reg_macrof1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "    return log_reg, log_reg_accuracy, log_reg_microf1, log_reg_macrof1\n",
    "\n",
    "log_reg, log_reg_accuracy, log_reg_microf1, log_reg_macrof1 = logistic_regression()\n",
    "\n",
    "print(\"Accuracy: \", log_reg_accuracy)\n",
    "print(\"Micro F1 scorre: \", log_reg_microf1)\n",
    "print(\"Macro F1 score: \", log_reg_macrof1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb418c4",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ad64566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9835493519441675\n",
      "Micro F1 scorre:  0.9835493519441675\n",
      "Macro F1 score:  0.8244815821560008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def randomForest():\n",
    "    rndFr = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "    rndFr.fit(X_train, y_train)\n",
    "    y_pred_rf = rndFr.predict(X_test)\n",
    "    rndFr_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "    rndFr_microf1 = f1_score(y_test, y_pred_rf, average=\"micro\")\n",
    "    rndFr_macrof1 = f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    return rndFr, rndFr_accuracy, rndFr_microf1, rndFr_macrof1\n",
    "\n",
    "rndFr, rndFr_accuracy, rndFr_microf1, rndFr_macrof1 = randomForest()\n",
    "\n",
    "print(\"Accuracy: \", rndFr_accuracy)\n",
    "print(\"Micro F1 scorre: \", rndFr_microf1)\n",
    "print(\"Macro F1 score: \", rndFr_macrof1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16264421-359e-47fe-b660-371d37860761",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3cd45c-116e-4cc1-a7f5-58cacda3dab3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Python version mismatch: module was compiled for Python 3.10, but the interpreter version is incompatible: 3.11.6 (main, Nov 14 2023, 09:36:21) [GCC 13.2.1 20230801].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mMLP\u001b[39m():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Define the MLP\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/tensorflow/__init__.py:45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF2_BEHAVIOR\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     46\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/tensorflow/python/tf2.py:21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Tools to help with the TensorFlow 2.0 transition.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mThis module is meant for TensorFlow internal implementation, not for users of\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mthe TensorFlow library. For that see tf.compat instead.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_tf2\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menable\u001b[39m():\n\u001b[1;32m     26\u001b[0m   \u001b[38;5;66;03m# Enables v2 behaviors.\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Python version mismatch: module was compiled for Python 3.10, but the interpreter version is incompatible: 3.11.6 (main, Nov 14 2023, 09:36:21) [GCC 13.2.1 20230801]."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def MLP():\n",
    "    # Define the MLP\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(64, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=30, batch_size=32,\n",
    "                        validation_data=(X_test, y_test))\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.evaluate(X_test, y_test)\n",
    "    y_proba = model.predict(X_test)\n",
    "    y_proba.round(2)\n",
    "\n",
    "    # Calculate scores\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mlp_microf1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "    mlp_macrof1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "    return model, history, test_accuracy, mlp_microf1, mlp_macrof1\n",
    "\n",
    "# Using the function\n",
    "mlp_model, mlp_history, mlp_test_accuracy, mlp_microf1, mlp_macrof1 = train_mlp_model()\n",
    "\n",
    "print(\"MLP Test Accuracy:\", mlp_test_accuracy)\n",
    "print(\"MLP Micro F1 Score:\", mlp_microf1)\n",
    "print(\"MLP Macro F1 Score:\", mlp_macrof1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9baf629-2f00-43ba-8d3e-6a6f87b7812a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
