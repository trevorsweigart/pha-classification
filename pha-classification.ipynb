{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c298b01-6a63-4ff2-876e-a697db93bd18",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92c4d4b8-7253-4035-84fb-a66b3e148004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddcf2c2-af93-4eda-a166-7f657d6216f5",
   "metadata": {},
   "source": [
    "# Load dataset into variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0af9944-1274-4595-af8b-60122d20cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_asteroid_data():\n",
    "    #csv_path = \"shuffled_asteroids_head.csv\"\n",
    "    csv_path = \"combined.csv\"\n",
    "    return pd.read_csv(csv_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b3b06c-cf68-4b3f-ab51-8c43d6f356f4",
   "metadata": {},
   "source": [
    "# Removing unneeded features and null features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48e4de44-996b-4b03-a0b3-eb402663bc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10027 entries, 0 to 10026\n",
      "Data columns (total 35 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         10027 non-null  object \n",
      " 1   neo        10027 non-null  object \n",
      " 2   pha        10027 non-null  int64  \n",
      " 3   H          10027 non-null  float64\n",
      " 4   epoch      10027 non-null  float64\n",
      " 5   epoch_mjd  10027 non-null  int64  \n",
      " 6   epoch_cal  10027 non-null  float64\n",
      " 7   e          10027 non-null  float64\n",
      " 8   a          10027 non-null  float64\n",
      " 9   q          10027 non-null  float64\n",
      " 10  i          10027 non-null  float64\n",
      " 11  om         10027 non-null  float64\n",
      " 12  w          10027 non-null  float64\n",
      " 13  ma         10027 non-null  float64\n",
      " 14  ad         10027 non-null  float64\n",
      " 15  n          10027 non-null  float64\n",
      " 16  tp         10027 non-null  float64\n",
      " 17  tp_cal     10027 non-null  float64\n",
      " 18  per        10027 non-null  float64\n",
      " 19  per_y      10027 non-null  float64\n",
      " 20  moid       10027 non-null  float64\n",
      " 21  moid_ld    10027 non-null  float64\n",
      " 22  sigma_e    10027 non-null  float64\n",
      " 23  sigma_a    10027 non-null  float64\n",
      " 24  sigma_q    10027 non-null  float64\n",
      " 25  sigma_i    10027 non-null  float64\n",
      " 26  sigma_om   10027 non-null  float64\n",
      " 27  sigma_w    10027 non-null  float64\n",
      " 28  sigma_ma   10027 non-null  float64\n",
      " 29  sigma_ad   10027 non-null  float64\n",
      " 30  sigma_n    10027 non-null  float64\n",
      " 31  sigma_tp   10027 non-null  float64\n",
      " 32  sigma_per  10027 non-null  float64\n",
      " 33  class      10027 non-null  object \n",
      " 34  rms        10027 non-null  float64\n",
      "dtypes: float64(30), int64(2), object(3)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "asteroids = load_asteroid_data()\n",
    "#asteroids.head()\n",
    "asteroids['pha'] = asteroids['pha'].map({'Y': 1, 'N': 0})\n",
    "asteroids = asteroids.dropna(subset=['pha'])\n",
    "asteroids = asteroids.dropna(subset=['sigma_e'])\n",
    "asteroids = asteroids.dropna(subset=['neo'])\n",
    "asteroids = asteroids.dropna(subset=['H'])\n",
    "asteroids = asteroids.dropna(subset=['ma'])\n",
    "asteroids = asteroids.drop(columns=['spkid', 'full_name', 'pdes', 'prefix', 'name', 'orbit_id', 'equinox', 'diameter', \"diameter_sigma\", \"albedo\"])\n",
    "asteroids.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc0bfc-6f92-4cd3-ba25-4d224f092d06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92dcfaed-b3cc-41f5-98ac-53ee0a590aba",
   "metadata": {},
   "source": [
    "# Converting object datatypes to numerical and standardizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88412f9f-6489-4447-8ca8-bcbb9bd58daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "#splitting features into numerical and categorical\n",
    "asteroids_num = asteroids.drop(columns=[\"id\", \"neo\", \"pha\", \"class\"])\n",
    "asteroids_id = asteroids[[\"id\"]]\n",
    "asteroids_cat = asteroids[[\"neo\", \"pha\", \"class\"]]\n",
    "\n",
    "#encode categorical features\n",
    "asteroid_cat_encoded = ordinal_encoder.fit_transform(asteroids_cat)\n",
    "\n",
    "#Normalizing numerical features\n",
    "std_scaler = StandardScaler()\n",
    "asteroid_num_scaled = std_scaler.fit_transform(asteroids_num)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde35eab-553d-45f9-b96d-8d6d39ec9468",
   "metadata": {},
   "source": [
    "# Creating features and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0918a8a-cfdf-4cc9-8f44-504fab176c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10027, 33)\n",
      "(10027,)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((asteroid_cat_encoded, asteroid_num_scaled), axis=1)\n",
    "X = np.delete(X, 2, 1)\n",
    "y = asteroid_cat_encoded[:,2]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5bdb61-9688-455b-a9e7-fc5004760300",
   "metadata": {},
   "source": [
    "# Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76483f02-dfca-41f5-8dd5-cdaf8f731937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (10027, 33)\n",
      "Shape of y: (10027,)\n",
      "First 5 rows of encoded and scaled features:\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.29673614e+00  1.03929223e-01\n",
      "   1.03929223e-01  1.03995726e-01  2.31920199e+00 -4.92661587e-01\n",
      "  -1.59988625e+00  1.34806429e+00 -9.21906249e-01 -6.17202834e-01\n",
      "  -3.57483218e-01  5.87423315e-01  8.88026015e-02 -5.39107911e-01\n",
      "  -3.86925034e-01 -4.04479899e-01 -4.04479899e-01 -1.42187069e+00\n",
      "  -1.42187069e+00 -2.10763836e-02 -1.88192184e-02 -1.74815949e-02\n",
      "  -1.49328072e-02 -2.12572595e-02 -1.70694683e-02 -1.79954534e-02\n",
      "  -1.91978427e-02 -2.03856698e-02 -1.63499702e-02 -1.87938453e-02\n",
      "  -8.11536226e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00 -5.03767731e-01  1.03929223e-01\n",
      "   1.03929223e-01  1.03995726e-01 -5.61953246e-01  3.10915130e-01\n",
      "   5.27056485e-01 -8.00627968e-01  6.74581191e-01  5.86429353e-01\n",
      "  -8.34517863e-01  3.70866815e-02 -4.07424830e-01 -4.95254348e-01\n",
      "  -3.81919403e-01  1.87759647e-01  1.87759647e-01  5.23204599e-01\n",
      "   5.23204599e-01 -2.10768444e-02 -1.88199473e-02 -1.74827889e-02\n",
      "  -1.49358155e-02 -2.12352491e-02 -1.70629885e-02 -1.79955897e-02\n",
      "  -1.91986548e-02 -2.03862928e-02 -1.63478331e-02 -1.87945879e-02\n",
      "  -3.71713413e-01]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.38247442e+00  1.03929223e-01\n",
      "   1.03929223e-01  1.03995726e-01  1.39526320e+00 -1.41628082e+00\n",
      "  -1.55645728e+00  1.08651603e+00  1.46671548e+00 -1.06870520e+00\n",
      "  -3.28253146e-01 -8.82432294e-01  1.32898376e+00 -2.79608586e-01\n",
      "  -3.56923366e-01 -9.90281452e-01 -9.90281452e-01 -1.42701667e+00\n",
      "  -1.42701667e+00 -2.10738466e-02 -1.88195095e-02 -1.74779858e-02\n",
      "  -1.49335866e-02 -2.12590468e-02 -1.70668499e-02 -1.79930114e-02\n",
      "  -1.91982165e-02 -2.03852942e-02 -1.63473821e-02 -1.87942271e-02\n",
      "  -9.24179476e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.46552892e-01  1.03929223e-01\n",
      "   1.03929223e-01  1.03995726e-01 -8.57920664e-01 -4.62224468e-01\n",
      "   5.62792641e-02 -5.87083332e-01  1.68460677e+00 -7.85585855e-01\n",
      "  -4.01689361e-01 -7.64778139e-01  6.37879296e-02 -5.28165565e-01\n",
      "  -3.86528752e-01 -3.83370788e-01 -3.83370788e-01  5.79818252e-04\n",
      "   5.79818252e-04 -2.10768328e-02 -1.88199646e-02 -1.74829724e-02\n",
      "  -1.49359735e-02 -2.12480577e-02 -1.70664782e-02 -1.79951564e-02\n",
      "  -1.91986682e-02 -2.03862941e-02 -1.63476475e-02 -1.87946102e-02\n",
      "  -4.14714155e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.03711745e-01  1.03929223e-01\n",
      "   1.03929223e-01  1.03995726e-01 -3.73317168e-01  1.25792281e-01\n",
      "   2.60483804e-01  5.40966276e-01  1.74507719e+00  7.62896557e-01\n",
      "   3.80539747e-03 -2.49151078e-02 -3.17614729e-01 -9.64432665e-01\n",
      "  -8.76116542e-01  4.50746051e-02  4.50746051e-02  2.51296938e-01\n",
      "   2.51296938e-01 -2.10768358e-02 -1.88199435e-02 -1.74828051e-02\n",
      "  -1.49358145e-02 -2.12587540e-02 -1.70704300e-02 -1.79957301e-02\n",
      "  -1.91986511e-02 -2.03862886e-02 -1.63485467e-02 -1.87945846e-02\n",
      "   1.16563137e-01]]\n",
      "\n",
      "First 5 rows of original categorical features:\n",
      "  neo  pha class\n",
      "0   Y    1   APO\n",
      "1   N    0   MBA\n",
      "2   Y    1   APO\n",
      "3   N    0   MBA\n",
      "4   N    0   MBA\n",
      "\n",
      "First 5 rows of original numerical features:\n",
      "      H      epoch  epoch_mjd   epoch_cal         e         a         q  \\\n",
      "0  18.5  2459000.5      59000  20200531.0  0.667639  2.152046  0.715256   \n",
      "1  12.2  2459000.5      59000  20200531.0  0.120700  2.739556  2.408893   \n",
      "2  18.8  2459000.5      59000  20200531.0  0.492244  1.476770  0.749838   \n",
      "3  13.1  2459000.5      59000  20200531.0  0.064515  2.174299  2.034024   \n",
      "4  12.9  2459000.5      59000  20200531.0  0.156509  2.604209  2.196627   \n",
      "\n",
      "           i          om           w  ...       sigma_q   sigma_i  sigma_om  \\\n",
      "0  20.521761   78.386879  114.434577  ...  1.946400e-07  0.000016  0.000020   \n",
      "1   2.873583  241.474620  238.729171  ...  9.328800e-08  0.000004  0.000091   \n",
      "2  18.373547  322.394387   67.809617  ...  5.009700e-07  0.000013  0.000015   \n",
      "3   4.627522  344.652876   97.046293  ...  7.771500e-08  0.000004  0.000050   \n",
      "4  13.892701  350.830178  256.952279  ...  9.191100e-08  0.000004  0.000016   \n",
      "\n",
      "    sigma_w  sigma_ma      sigma_ad       sigma_n  sigma_tp  sigma_per  \\\n",
      "0  0.000031  0.000024  4.080400e-07  5.324400e-08  0.000026   0.000197   \n",
      "1  0.000093  0.000021  1.279500e-08  1.358800e-09  0.000095   0.000010   \n",
      "2  0.000056  0.000082  2.261000e-07  8.452400e-08  0.000110   0.000101   \n",
      "3  0.000059  0.000031  6.269600e-09  1.249100e-09  0.000101   0.000005   \n",
      "4  0.000021  0.000017  1.460900e-08  1.706400e-09  0.000072   0.000011   \n",
      "\n",
      "       rms  \n",
      "0  0.40820  \n",
      "1  0.43643  \n",
      "2  0.40097  \n",
      "3  0.43367  \n",
      "4  0.46777  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the dataset\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "# Print the first 5 rows of the encoded and scaled features\n",
    "print(\"First 5 rows of encoded and scaled features:\")\n",
    "print(X[:5, :])\n",
    "\n",
    "print(\"\\nFirst 5 rows of original categorical features:\")\n",
    "print(asteroids_cat.head())\n",
    "\n",
    "print(\"\\nFirst 5 rows of original numerical features:\")\n",
    "print(asteroids_num.head()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528090d-ad59-40b9-bf1c-dbdd05470a67",
   "metadata": {},
   "source": [
    "# Training and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c72da619-a5fc-4da9-a7ee-4ac824b3b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61171946-df6f-4cdc-8ccb-813f5bdf4a82",
   "metadata": {},
   "source": [
    "# Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0453953-5f1c-41f6-af2c-035730ae17ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Logistic Regression:\n",
      "[[  15   30    0    0    0    0    0    0    0    0]\n",
      " [   0  358    0    2    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    3    0   38    0    0    0    0    0    0]\n",
      " [   0    0    1    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0   16    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1416    2    0    0]\n",
      " [   0    0    0    0    0    2   13   24    0    0]\n",
      " [   0    0    0    0    0    0   45    0   25    1]\n",
      " [   0    0    0    0    0    0    0    0    0   15]]\n",
      "Accuracy:  0.9506480558325024\n",
      "Micro F1 scorre:  0.9506480558325024\n",
      "Macro F1 score:  0.6539133467541507\n",
      "RMSE:  0.3586281605331876\n",
      "MAE:  0.07577268195413758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logistic_regression():\n",
    "    # Initialization and fitting logisitic regression\n",
    "    log_reg = LogisticRegression(solver=\"newton-cg\", random_state=42)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    #Make predictions\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "\n",
    "    #Model metrics\n",
    "    log_reg_accuracy = accuracy_score(y_test, y_pred)\n",
    "    log_reg_microf1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "    log_reg_macrof1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    # Calculate RMSE and MAE\n",
    "    log_reg_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    log_reg_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    cm_log_reg = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"Confusion Matrix for Logistic Regression:\")\n",
    "    print(cm_log_reg)\n",
    "\n",
    "    return log_reg, log_reg_accuracy, log_reg_microf1, log_reg_macrof1, log_reg_rmse, log_reg_mae\n",
    "\n",
    "log_reg, log_reg_accuracy, log_reg_microf1, log_reg_macrof1, log_reg_rmse, log_reg_mae = logistic_regression()\n",
    "\n",
    "print(\"Accuracy: \", log_reg_accuracy)\n",
    "print(\"Micro F1 scorre: \", log_reg_microf1)\n",
    "print(\"Macro F1 score: \", log_reg_macrof1)\n",
    "print(\"RMSE: \", log_reg_rmse)\n",
    "print(\"MAE: \", log_reg_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb418c4",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ad64566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9835493519441675\n",
      "Micro F1 scorre:  0.9835493519441675\n",
      "Macro F1 score:  0.8244815821560008\n",
      "RMSE:  0.15468747639656608\n",
      "MAE:  0.01794616151545364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def randomForest():\n",
    "    rndFr = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "    rndFr.fit(X_train, y_train)\n",
    "    y_pred_rf = rndFr.predict(X_test)\n",
    "    rndFr_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "    rndFr_microf1 = f1_score(y_test, y_pred_rf, average=\"micro\")\n",
    "    rndFr_macrof1 = f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    rndFr_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "    rndFr_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "    return rndFr, rndFr_accuracy, rndFr_microf1, rndFr_macrof1, rndFr_rmse, rndFr_mae\n",
    "\n",
    "rndFr, rndFr_accuracy, rndFr_microf1, rndFr_macrof1, rndFr_rmse, rndFr_mae = randomForest()\n",
    "\n",
    "print(\"Accuracy: \", rndFr_accuracy)\n",
    "print(\"Micro F1 scorre: \", rndFr_microf1)\n",
    "print(\"Macro F1 score: \", rndFr_macrof1)\n",
    "print(\"RMSE: \", rndFr_rmse)\n",
    "print(\"MAE: \", rndFr_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16264421-359e-47fe-b660-371d37860761",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c3cd45c-116e-4cc1-a7f5-58cacda3dab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 20:07:50.291111: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-03 20:07:50.292476: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-03 20:07:50.316204: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-03 20:07:50.316229: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-03 20:07:50.316896: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-03 20:07:50.321271: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-03 20:07:50.321783: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-03 20:07:50.866271: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "251/251 [==============================] - 1s 2ms/step - loss: -126650515456.0000 - accuracy: 0.1789 - val_loss: -907883053056.0000 - val_accuracy: 0.1795\n",
      "Epoch 2/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -15765918973952.0000 - accuracy: 0.1798 - val_loss: -51431851687936.0000 - val_accuracy: 0.1795\n",
      "Epoch 3/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -207432408104960.0000 - accuracy: 0.1798 - val_loss: -451512933285888.0000 - val_accuracy: 0.1795\n",
      "Epoch 4/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -1078862096105472.0000 - accuracy: 0.1798 - val_loss: -1890992496050176.0000 - val_accuracy: 0.1795\n",
      "Epoch 5/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -3647728877830144.0000 - accuracy: 0.1798 - val_loss: -5593777754341376.0000 - val_accuracy: 0.1795\n",
      "Epoch 6/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -9443081526968320.0000 - accuracy: 0.1798 - val_loss: -13224289129988096.0000 - val_accuracy: 0.1795\n",
      "Epoch 7/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -20068627680067584.0000 - accuracy: 0.1798 - val_loss: -26463617087963136.0000 - val_accuracy: 0.1795\n",
      "Epoch 8/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -37956477125656576.0000 - accuracy: 0.1798 - val_loss: -47732256483049472.0000 - val_accuracy: 0.1795\n",
      "Epoch 9/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -65853797246697472.0000 - accuracy: 0.1798 - val_loss: -79722263825350656.0000 - val_accuracy: 0.1795\n",
      "Epoch 10/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -105710002831884288.0000 - accuracy: 0.1798 - val_loss: -124780868806901760.0000 - val_accuracy: 0.1795\n",
      "Epoch 11/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -161398651871035392.0000 - accuracy: 0.1798 - val_loss: -186080162473836544.0000 - val_accuracy: 0.1795\n",
      "Epoch 12/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -232467905214676992.0000 - accuracy: 0.1798 - val_loss: -265416592207118336.0000 - val_accuracy: 0.1795\n",
      "Epoch 13/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -326926691458875392.0000 - accuracy: 0.1798 - val_loss: -367618998327574528.0000 - val_accuracy: 0.1795\n",
      "Epoch 14/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -450262793396944896.0000 - accuracy: 0.1798 - val_loss: -496114696017936384.0000 - val_accuracy: 0.1795\n",
      "Epoch 15/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -598378691969417216.0000 - accuracy: 0.1798 - val_loss: -653511778398896128.0000 - val_accuracy: 0.1795\n",
      "Epoch 16/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -775749708738985984.0000 - accuracy: 0.1798 - val_loss: -843862255056453632.0000 - val_accuracy: 0.1795\n",
      "Epoch 17/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -1000930102424371200.0000 - accuracy: 0.1798 - val_loss: -1071291218740117504.0000 - val_accuracy: 0.1795\n",
      "Epoch 18/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -1251872740743315456.0000 - accuracy: 0.1798 - val_loss: -1340455857107763200.0000 - val_accuracy: 0.1795\n",
      "Epoch 19/75\n",
      "251/251 [==============================] - 0s 2ms/step - loss: -1562473780473757696.0000 - accuracy: 0.1798 - val_loss: -1655661926413238272.0000 - val_accuracy: 0.1795\n",
      "Epoch 20/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -1918860958285955072.0000 - accuracy: 0.1798 - val_loss: -2019400026651885568.0000 - val_accuracy: 0.1795\n",
      "Epoch 21/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -2305239514768998400.0000 - accuracy: 0.1798 - val_loss: -2431701356466143232.0000 - val_accuracy: 0.1795\n",
      "Epoch 22/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -2791365628684926976.0000 - accuracy: 0.1798 - val_loss: -2910564234007937024.0000 - val_accuracy: 0.1795\n",
      "Epoch 23/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -3319455016191787008.0000 - accuracy: 0.1798 - val_loss: -3453376357088624640.0000 - val_accuracy: 0.1795\n",
      "Epoch 24/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -3924479706195296256.0000 - accuracy: 0.1798 - val_loss: -4063311191143874560.0000 - val_accuracy: 0.1795\n",
      "Epoch 25/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -4593280468656324608.0000 - accuracy: 0.1798 - val_loss: -4751471329713061888.0000 - val_accuracy: 0.1795\n",
      "Epoch 26/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -5368349029941903360.0000 - accuracy: 0.1798 - val_loss: -5521817213679435776.0000 - val_accuracy: 0.1795\n",
      "Epoch 27/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -6206285741958365184.0000 - accuracy: 0.1798 - val_loss: -6377927753391407104.0000 - val_accuracy: 0.1795\n",
      "Epoch 28/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -7188046271469322240.0000 - accuracy: 0.1798 - val_loss: -7332820067010215936.0000 - val_accuracy: 0.1795\n",
      "Epoch 29/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -8201684391848574976.0000 - accuracy: 0.1798 - val_loss: -8386174196652179456.0000 - val_accuracy: 0.1795\n",
      "Epoch 30/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -9388051390904926208.0000 - accuracy: 0.1798 - val_loss: -9544763683700211712.0000 - val_accuracy: 0.1795\n",
      "Epoch 31/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -10564678366206623744.0000 - accuracy: 0.1798 - val_loss: -10815916773153439744.0000 - val_accuracy: 0.1795\n",
      "Epoch 32/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -12063251142214156288.0000 - accuracy: 0.1798 - val_loss: -12206494417569185792.0000 - val_accuracy: 0.1795\n",
      "Epoch 33/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -13589209454334705664.0000 - accuracy: 0.1798 - val_loss: -13740257063223689216.0000 - val_accuracy: 0.1795\n",
      "Epoch 34/75\n",
      "251/251 [==============================] - 0s 2ms/step - loss: -15151443953590468608.0000 - accuracy: 0.1798 - val_loss: -15396792276747288576.0000 - val_accuracy: 0.1795\n",
      "Epoch 35/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -16989376595464552448.0000 - accuracy: 0.1798 - val_loss: -17197979240021098496.0000 - val_accuracy: 0.1795\n",
      "Epoch 36/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -18992150219598069760.0000 - accuracy: 0.1798 - val_loss: -19156824076090081280.0000 - val_accuracy: 0.1795\n",
      "Epoch 37/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -21266641754257358848.0000 - accuracy: 0.1798 - val_loss: -21297872282532708352.0000 - val_accuracy: 0.1795\n",
      "Epoch 38/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -23488642603806621696.0000 - accuracy: 0.1798 - val_loss: -23591996696817565696.0000 - val_accuracy: 0.1795\n",
      "Epoch 39/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -25802775930693746688.0000 - accuracy: 0.1798 - val_loss: -26046907094478618624.0000 - val_accuracy: 0.1795\n",
      "Epoch 40/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -28513824159114985472.0000 - accuracy: 0.1798 - val_loss: -28698737825651097600.0000 - val_accuracy: 0.1795\n",
      "Epoch 41/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -31299392887620370432.0000 - accuracy: 0.1798 - val_loss: -31535499815545733120.0000 - val_accuracy: 0.1795\n",
      "Epoch 42/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -34437034035432652800.0000 - accuracy: 0.1798 - val_loss: -34587339473972887552.0000 - val_accuracy: 0.1795\n",
      "Epoch 43/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -37351579875922673664.0000 - accuracy: 0.1798 - val_loss: -37836578852981178368.0000 - val_accuracy: 0.1795\n",
      "Epoch 44/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -41293777662243766272.0000 - accuracy: 0.1798 - val_loss: -41347842848004767744.0000 - val_accuracy: 0.1795\n",
      "Epoch 45/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -45214627330799960064.0000 - accuracy: 0.1798 - val_loss: -45112403535742369792.0000 - val_accuracy: 0.1795\n",
      "Epoch 46/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -49072971962340343808.0000 - accuracy: 0.1798 - val_loss: -49119406537404579840.0000 - val_accuracy: 0.1795\n",
      "Epoch 47/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -53830123369122496512.0000 - accuracy: 0.1798 - val_loss: -53429056711681900544.0000 - val_accuracy: 0.1795\n",
      "Epoch 48/75\n",
      "251/251 [==============================] - 0s 2ms/step - loss: -58368471961977225216.0000 - accuracy: 0.1798 - val_loss: -57977819878674923520.0000 - val_accuracy: 0.1795\n",
      "Epoch 49/75\n",
      "251/251 [==============================] - 0s 2ms/step - loss: -62789067257543655424.0000 - accuracy: 0.1798 - val_loss: -62762696570663075840.0000 - val_accuracy: 0.1795\n",
      "Epoch 50/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -68154824738578890752.0000 - accuracy: 0.1798 - val_loss: -67853949978707755008.0000 - val_accuracy: 0.1795\n",
      "Epoch 51/75\n",
      "251/251 [==============================] - 0s 2ms/step - loss: -73813927523858251776.0000 - accuracy: 0.1798 - val_loss: -73281812274526289920.0000 - val_accuracy: 0.1795\n",
      "Epoch 52/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -79578702172659908608.0000 - accuracy: 0.1798 - val_loss: -79013201352262156288.0000 - val_accuracy: 0.1795\n",
      "Epoch 53/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -85744226819553361920.0000 - accuracy: 0.1798 - val_loss: -85120399106325348352.0000 - val_accuracy: 0.1795\n",
      "Epoch 54/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -92364659009276346368.0000 - accuracy: 0.1798 - val_loss: -91546323291048247296.0000 - val_accuracy: 0.1795\n",
      "Epoch 55/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -99472535489918009344.0000 - accuracy: 0.1798 - val_loss: -98351860462330576896.0000 - val_accuracy: 0.1795\n",
      "Epoch 56/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -106405589621743288320.0000 - accuracy: 0.1798 - val_loss: -105500374892734840832.0000 - val_accuracy: 0.1795\n",
      "Epoch 57/75\n",
      "251/251 [==============================] - 0s 2ms/step - loss: -114340958553449168896.0000 - accuracy: 0.1798 - val_loss: -113093663766807052288.0000 - val_accuracy: 0.1795\n",
      "Epoch 58/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -122437278395275411456.0000 - accuracy: 0.1798 - val_loss: -121097351953016422400.0000 - val_accuracy: 0.1795\n",
      "Epoch 59/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -131001154561697120256.0000 - accuracy: 0.1798 - val_loss: -129541583662150057984.0000 - val_accuracy: 0.1795\n",
      "Epoch 60/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -138635714704229531648.0000 - accuracy: 0.1798 - val_loss: -138287292663526850560.0000 - val_accuracy: 0.1795\n",
      "Epoch 61/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -149546001460883357696.0000 - accuracy: 0.1798 - val_loss: -147572562806978904064.0000 - val_accuracy: 0.1795\n",
      "Epoch 62/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -159209864244104265728.0000 - accuracy: 0.1798 - val_loss: -157317455199120392192.0000 - val_accuracy: 0.1795\n",
      "Epoch 63/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -168197518580149911552.0000 - accuracy: 0.1798 - val_loss: -167459420822470393856.0000 - val_accuracy: 0.1795\n",
      "Epoch 64/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -180434273756738748416.0000 - accuracy: 0.1798 - val_loss: -178168259456729612288.0000 - val_accuracy: 0.1795\n",
      "Epoch 65/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -193391815979939397632.0000 - accuracy: 0.1798 - val_loss: -189537491162910162944.0000 - val_accuracy: 0.1795\n",
      "Epoch 66/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -203660586080297549824.0000 - accuracy: 0.1798 - val_loss: -201263949798908624896.0000 - val_accuracy: 0.1795\n",
      "Epoch 67/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -216632606672612753408.0000 - accuracy: 0.1798 - val_loss: -213642146151294566400.0000 - val_accuracy: 0.1795\n",
      "Epoch 68/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -231102883381586690048.0000 - accuracy: 0.1798 - val_loss: -226534579693944832000.0000 - val_accuracy: 0.1795\n",
      "Epoch 69/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -244341126525312040960.0000 - accuracy: 0.1798 - val_loss: -240100195827770720256.0000 - val_accuracy: 0.1795\n",
      "Epoch 70/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -258479104432093003776.0000 - accuracy: 0.1798 - val_loss: -254171182690094546944.0000 - val_accuracy: 0.1795\n",
      "Epoch 71/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -273752974607389818880.0000 - accuracy: 0.1798 - val_loss: -268927297237918154752.0000 - val_accuracy: 0.1795\n",
      "Epoch 72/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -287783006860602245120.0000 - accuracy: 0.1798 - val_loss: -284219041074236096512.0000 - val_accuracy: 0.1795\n",
      "Epoch 73/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -304405581978994212864.0000 - accuracy: 0.1798 - val_loss: -300311000677156388864.0000 - val_accuracy: 0.1795\n",
      "Epoch 74/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -324965710546591547392.0000 - accuracy: 0.1798 - val_loss: -317186797721471680512.0000 - val_accuracy: 0.1795\n",
      "Epoch 75/75\n",
      "251/251 [==============================] - 0s 1ms/step - loss: -337917711231188205568.0000 - accuracy: 0.1798 - val_loss: -334602358218001743872.0000 - val_accuracy: 0.1795\n",
      "63/63 [==============================] - 0s 622us/step - loss: -334602358218001743872.0000 - accuracy: 0.1795\n",
      "63/63 [==============================] - 0s 708us/step\n",
      "MLP Test Accuracy: 0.1794616151545364\n",
      "MLP Micro F1 Score: 0.17946161515453637\n",
      "MLP Macro F1 Score: 0.0338123415046492\n",
      "RMSE:  5.4386820290728455\n",
      "MAE:  4.8325024925224325\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def MLP():\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # Define the MLP\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(128, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=75, batch_size=32,\n",
    "                        validation_data=(X_test, y_test))\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.evaluate(X_test, y_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred.round(2)\n",
    "\n",
    "    # Calculate scores\n",
    "    mlp_accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlp_microf1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "    mlp_macrof1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    mlp_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mlp_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return model, history, mlp_accuracy, mlp_microf1, mlp_macrof1, mlp_rmse, mlp_mae\n",
    "\n",
    "mlp_model, mlp_history, mlp_accuracy, mlp_microf1, mlp_macrof1, mlp_rmse, mlp_mae = MLP()\n",
    "\n",
    "print(\"MLP Test Accuracy:\", mlp_accuracy)\n",
    "print(\"MLP Micro F1 Score:\", mlp_microf1)\n",
    "print(\"MLP Macro F1 Score:\", mlp_macrof1)\n",
    "print(\"RMSE: \", mlp_rmse)\n",
    "print(\"MAE: \", mlp_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b66d5-32a4-41d5-91a0-5d5cf4a10e53",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "897cf7c1-391e-4733-a23d-8f8bd68b1194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9925224327018943\n",
      "XGBoost Micro F1 Score: 0.9925224327018943\n",
      "XGBoost Macro F1 Score: 0.8677746762929767\n",
      "RMSE:  0.15944820103582016\n",
      "MAE:  0.012462612163509471\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def xgboost_clf():\n",
    "    # Initialize XGBoost\n",
    "    xgb_clf = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "    # Model metrics\n",
    "    xgb_accuracy = accuracy_score(y_test, y_pred)\n",
    "    xgb_microf1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "    xgb_macrof1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    xgb_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    xgb_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return xgb_clf, xgb_accuracy, xgb_microf1, xgb_macrof1, xgb_rmse, xgb_mae\n",
    "\n",
    "xgb_model, xgb_accuracy, xgb_microf1, xgb_macrof1, xgb_rmse, xgb_mae = xgboost_clf()\n",
    "\n",
    "print(\"XGBoost Accuracy:\", xgb_accuracy)\n",
    "print(\"XGBoost Micro F1 Score:\", xgb_microf1)\n",
    "print(\"XGBoost Macro F1 Score:\", xgb_macrof1)\n",
    "print(\"RMSE: \", xgb_rmse)\n",
    "print(\"MAE: \", xgb_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922cd839-a50c-4b98-9354-0a96d02a35ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
